<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts</title>
    <style>
        /* ÂÖ®Â±ÄÊ†∑ÂºèÈáçÁΩÆ‰∏éÂü∫Á°ÄËÆæÁΩÆ */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Helvetica Neue', Arial, sans-serif;
            background-color: #ffffff;
            color: #212529;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        /* Ê†áÈ¢òÂ±ÇÁ∫ßÊ†∑Âºè */
        h1 {
            font-size: 28px;
            font-weight: 700;
            text-align: center;
            margin-bottom: 20px;
            line-height: 1.3;
        }
        h2 {
            font-size: 24px;
            font-weight: 600;
            margin: 40px 0 15px;
            padding-bottom: 8px;
            border-bottom: 1px solid #e9ecef;
        }
        h3 {
            font-size: 20px;
            font-weight: 600;
            margin: 30px 0 12px;
        }

        /* ‰ΩúËÄÖ‰∏éÂçï‰ΩçÊ†∑Âºè */
        .authors {
            text-align: center;
            font-size: 18px;
            margin-bottom: 10px;
        }
        .authors a {
            color: #212529;
            text-decoration: none;
        }
        .affiliations {
            text-align: center;
            font-size: 16px;
            color: #495057;
            margin-bottom: 15px;
        }
        .conference {
            text-align: center;
            font-size: 18px;
            font-weight: 600;
            color: #dc3545;
            margin-bottom: 25px;
        }

        /* Êñ∞Â¢ûÔºöPDF/Code/Demo ÊåâÈíÆÊ†∑Âºè */
        .buttons {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 35px;
            flex-wrap: wrap;
        }
        .btn {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 10px 20px;
            background-color: #212529;
            color: #ffffff;
            text-decoration: none;
            border-radius: 6px;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.2s ease;
            border: 1px solid #212529;
        }
        .btn:hover {
            background-color: #495057;
            border-color: #495057;
            transform: translateY(-1px);
        }
        .btn-outline {
            background-color: #ffffff;
            color: #212529;
        }
        .btn-outline:hover {
            background-color: #f8f9fa;
            color: #212529;
        }

        /* È°∂ÈÉ®È¢ÑËßàÂõæÂÆπÂô® */
        .top-preview {
            display: flex;
            justify-content: space-around;
            align-items: center;
            flex-wrap: wrap;
            gap: 20px;
            margin-bottom: 40px;
        }
        .preview-img {
            max-width: 48%;
            height: auto;
            border: 1px solid #dee2e6;
            border-radius: 4px;
        }

        /* ÊÆµËêΩÊñáÊú¨ */
        p {
            font-size: 16px;
            margin-bottom: 15px;
            text-align: justify;
        }

        /* Ë°®Ê†ºÈÄöÁî®Ê†∑Âºè */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 14px;
            overflow-x: auto;
            display: block;
        }
        table th, table td {
            border: 1px solid #dee2e6;
            padding: 8px 6px;
            text-align: center;
            white-space: nowrap;
        }
        table th {
            background-color: #f8f9fa;
            font-weight: 600;
        }
        .gold {
            color: #ffc107;
            font-weight: 700;
        }
        .silver {
            color: #6c757d;
            font-weight: 700;
        }
        .bronze {
            color: #cd7f32;
            font-weight: 700;
        }
        .closed-source {
            color: #dc3545;
        }
        .open-source {
            color: #0d6efd;
        }
        /* Ë°®Ê†ºËØ¥ÊòéÊñáÊú¨ */
        .table-note {
            font-size: 14px;
            color: #495057;
            margin: -10px 0 20px;
        }

        /* Êï∞ÊçÆÈõÜÁªüËÆ°Âç°Áâá */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .stats-card {
            border: 1px solid #dee2e6;
            border-radius: 6px;
            padding: 15px;
        }

        /* Á§∫‰æãÂå∫Âùó */
        .example-block {
            border: 1px solid #dee2e6;
            border-radius: 6px;
            padding: 20px;
            margin: 20px 0;
            background-color: #f8f9fa;
        }
        .example-question {
            font-size: 16px;
            margin-bottom: 15px;
        }
        .example-answer {
            font-size: 15px;
            font-weight: 600;
            margin-top: 10px;
        }
        .example-meta {
            font-size: 14px;
            color: #495057;
            margin-top: 5px;
        }
        .img-placeholder {
            width: 100%;
            max-width: 400px;
            height: 200px;
            background-color: #e9ecef;
            border: 1px dashed #adb5bd;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #6c757d;
            margin: 10px 0;
            border-radius: 4px;
        }

        /* ÂõæË°®ÂÆπÂô® */
        .chart-row {
            display: flex;
            justify-content: space-around;
            align-items: center;
            flex-wrap: wrap;
            gap: 20px;
            margin: 30px 0;
        }
        .chart-item {
            max-width: 48%;
            text-align: center;
        }
        .chart-img {
            width: 100%;
            height: auto;
            border: 1px solid #dee2e6;
            border-radius: 4px;
            margin-bottom: 8px;
        }
        .chart-caption {
            font-size: 14px;
            color: #495057;
        }

        /* BibTeX ‰ª£Á†ÅÂùó */
        pre {
            background-color: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 6px;
            padding: 20px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', Courier, monospace;
            font-size: 14px;
            line-height: 1.5;
        }

        /* È°µËÑö */
        footer {
            margin-top: 60px;
            text-align: center;
            padding-top: 30px;
            border-top: 1px solid #e9ecef;
            font-size: 14px;
            color: #6c757d;
        }
        .footer-logos {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 40px;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        /* ÂìçÂ∫îÂºèÈÄÇÈÖç */
        @media (max-width: 768px) {
            h1 {
                font-size: 22px;
            }
            h2 {
                font-size: 20px;
            }
            .preview-img, .chart-item {
                max-width: 100%;
            }
            table {
                font-size: 12px;
            }
            .buttons {
                gap: 10px;
            }
            .btn {
                padding: 8px 16px;
                font-size: 14px;
            }
        }
    </style>
</head>
<body>
    <!-- È°µÈù¢Â§¥ÈÉ® -->
    <header>
        <h1>MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts</h1>
        <div class="authors">
            <a href="#">Peijie Wang</a><sup>1,2</sup>,
            <a href="#">Zhongzhi Li</a><sup>1,2</sup>,
            <a href="#">Dekang Ran</a><sup>1,2</sup>,
            <a href="#">Fei Yin</a><sup>1,2</sup>,
            <a href="#">Chenglin Liu</a><sup>1,2</sup>
        </div>
        <div class="affiliations">
            <sup>1</sup> MAIS, Institute of Automation of Chinese Academy of Sciences<br>
            <sup>2</sup> School of Artificial Intelligence, University of Chinese Academy of Sciences
        </div>
        <div class="conference">CVPR 2025</div>

        <!-- Êñ∞Â¢ûÔºöPDF/Code/Demo ÊåâÈíÆÂå∫Âüü -->
        <div class="buttons">
            <a href="#" class="btn" id="btn-pdf">
                <span>üìÑ</span>
                <span>Paper</span>
            </a>
            <a href="#" class="btn btn-outline" id="btn-code">
                <span>üíª</span>
                <span>Code</span>
            </a>
            <a href="#" class="btn btn-outline" id="btn-demo">
                <span>üöÄ</span>
                <span>Demo</span>
            </a>
        </div>

        <!-- È°∂ÈÉ®ÊÄßËÉΩÂØπÊØîÈ¢ÑËßàÂõæ -->
        <div class="top-preview">
            <div class="preview-img">
                <div class="img-placeholder">
                    Performance comparison of 6 MLLMs on 11 subjects
                </div>
            </div>
            <div class="preview-img">
                <div class="img-placeholder">
                    Performance comparison on 3 question types<br>
                    SAR: Step Accuracy Rate, QCR: Question Completeness Rate
                </div>
            </div>
        </div>
    </header>

    <!-- ‰ªãÁªçÈÉ®ÂàÜ -->
    <section>
        <h2>Introduction</h2>
        <p>
            Multimodal Large Language Models (MLLMs) have shown promising capabilities in mathematical reasoning within visual contexts across various datasets. However, most existing multimodal math benchmarks are limited to single-visual contexts, which diverges from the multi-visual scenarios commonly encountered in real-world mathematical applications. To address this gap, we introduce MV-MATH: a meticulously curated dataset of 2,009 high-quality mathematical problems. Each problem integrates multiple images interleaved with text, derived from authentic K-12 scenarios, and enriched with detailed annotations.
        </p>
        <p>
            MV-MATH includes multiple-choice, free-form, and multi-step questions, covering 11 subject areas across 3 difficulty levels, and serves as a comprehensive and rigorous benchmark for assessing MLLMs‚Äô mathematical reasoning in multi-visual contexts. Through extensive experimentation, we observe that MLLMs encounter substantial challenges in multi-visual math tasks, with a considerable performance gap relative to human capabilities on MV-MATH. Furthermore, we analyze the performance and error patterns of various models, providing insights into MLLMs' mathematical reasoning capabilities within multi-visual settings.
        </p>
    </section>

    <!-- ÊéíË°åÊ¶úÈÉ®ÂàÜ -->
    <section>
        <h2>Leaderboard on MV-MATH</h2>
        <p class="table-note">Accuracy scores of models on our MV-MATH benchmark</p>
        <table>
            <thead>
                <tr>
                    <th>Model</th>
                    <th>Overall</th>
                    <th>AG</th>
                    <th>Algebra</th>
                    <th>MG</th>
                    <th>Combinatorics</th>
                    <th>TG</th>
                    <th>Logic</th>
                    <th>SG</th>
                    <th>Arithmetic</th>
                    <th>CG</th>
                    <th>DG</th>
                    <th>Statistics</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Seed1.5-VL (thinking)<span class="gold">ü•á</span></td>
                    <td>72.9</td>
                    <td>80.6</td>
                    <td>79.5</td>
                    <td>69.8</td>
                    <td>70.7</td>
                    <td>68.3</td>
                    <td>77.3</td>
                    <td>74.5</td>
                    <td>94.8</td>
                    <td>64.9</td>
                    <td>74.1</td>
                    <td>80.0</td>
                </tr>
                <tr>
                    <td>Qwen-vl-max<span class="silver">ü•à</span></td>
                    <td>42.4</td>
                    <td>44.4</td>
                    <td>51.5</td>
                    <td>42.2</td>
                    <td>41.5</td>
                    <td>41.1</td>
                    <td>40.9</td>
                    <td>47.6</td>
                    <td>56.2</td>
                    <td>28.8</td>
                    <td>46.8</td>
                    <td>60.0</td>
                </tr>
                <tr>
                    <td>Qwen2.5VL-Instruct-32B<span class="bronze">ü•â</span></td>
                    <td>37.1</td>
                    <td>36.2</td>
                    <td>43.1</td>
                    <td>38.2</td>
                    <td>48.8</td>
                    <td>33.1</td>
                    <td>40.9</td>
                    <td>43.8</td>
                    <td>62.5</td>
                    <td>25.5</td>
                    <td>42.4</td>
                    <td>60.0</td>
                </tr>
                <tr>
                    <td class="closed-source">Claude-3.5</td>
                    <td>33.9</td>
                    <td>32.7</td>
                    <td>38.1</td>
                    <td>34.3</td>
                    <td>46.7</td>
                    <td>33.3</td>
                    <td>29.8</td>
                    <td>36.3</td>
                    <td>54.2</td>
                    <td>27.0</td>
                    <td>38.2</td>
                    <td>41.1</td>
                </tr>
                <tr>
                    <td class="closed-source">GPT-4o</td>
                    <td>32.1</td>
                    <td>28.7</td>
                    <td>36.7</td>
                    <td>34.4</td>
                    <td>39.4</td>
                    <td>30.6</td>
                    <td>29.8</td>
                    <td>38.2</td>
                    <td>41.7</td>
                    <td>20.8</td>
                    <td>44.3</td>
                    <td>47.0</td>
                </tr>
                <tr>
                    <td class="closed-source">Gemini-1.5-Pro</td>
                    <td>29.1</td>
                    <td>29.9</td>
                    <td>32.9</td>
                    <td>28.3</td>
                    <td>28.0</td>
                    <td>30.5</td>
                    <td>40.5</td>
                    <td>33.9</td>
                    <td>42.7</td>
                    <td>21.7</td>
                    <td>30.6</td>
                    <td>35.2</td>
                </tr>
                <!-- Êõ¥Â§öÊ®°ÂûãË°åÂèØ‰ª•Âú®Ê≠§Â§ÑÊ∑ªÂä† -->
            </tbody>
        </table>
        <p class="table-note">
            Models: Closed-source models are highlighted in red, while open-source models are highlighted in blue.<br>
            Mathematical Subjects: AG: Analytic Geometry, MG: Metric Geometry, TG: Transformation Geometry, SG: Solid Geometry, CG: Combinatorial Geometry, DG: Descriptive Geometry.
        </p>
    </section>

    <!-- Êï∞ÊçÆÈõÜËØ¶ÊÉÖ -->
    <section>
        <h2>MV-MATH Dataset</h2>
        <h3>Overview</h3>
        <p>
            MV-MATH is a meticulously annotated dataset designed to evaluate the mathematical reasoning capabilities of MLLMs in multi-visual contexts. Each sample in MV-MATH consists of interleaved multi-image and text. It comprises 2,009 multi-image questions, with some questions containing up to 8 images. It includes three types: multiple-choice, free-form and multi-step questions.
        </p>
        <p>
            MV-MATH is organized into 11 subjects over 3 difficulty levels, including Analytic Geometry, Algebra, Metric Geometry, Combinatorics, Transformation Geometry, Logic, Solid Geometry, Arithmetic, Combinatorial Geometry, Descriptive Geometry and Statistics, covering a range of scenarios from the K-12 mathematics curriculum.
        </p>
        <p>
            Based on image relevance, we categorize MV-MATH into two subsets: a mutually dependent set (MD), where images are interrelated and understanding one image necessitates information from another; and an independent set (ID), where images are unrelated and can be interpreted independently without reference to other images.
        </p>

        <!-- Ê†∏ÂøÉÁªüËÆ°Ë°®Ê†º -->
        <h3>Key statistics of MV-MATH</h3>
        <table style="max-width: 600px; margin: 20px auto;">
            <thead>
                <tr>
                    <th>Statistics</th>
                    <th>Number</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Total Questions</td>
                    <td>2009</td>
                </tr>
                <tr>
                    <td>*multiple-choice questions</td>
                    <td>1109</td>
                </tr>
                <tr>
                    <td>*Free-form questions</td>
                    <td>900</td>
                </tr>
                <tr>
                    <td>-one-step questions</td>
                    <td>800</td>
                </tr>
                <tr>
                    <td>-multi-step questions</td>
                    <td>100</td>
                </tr>
                <tr>
                    <td>Difficulties (Easy: Medium: Hard)</td>
                    <td>27%:48%:25%</td>
                </tr>
                <tr>
                    <td>Total images</td>
                    <td>6061</td>
                </tr>
            </tbody>
        </table>

        <!-- Êï∞ÊçÆÈõÜÁ§∫‰æã -->
        <h3>Sampled MV-MATH examples from each question type</h3>
        <div class="example-block">
            <h4>Multiple Choice</h4>
            <div class="example-question">
                Question: Unfolding the given square as shown in &lt;image_1&gt;, which of the following could be the flat unfolded pattern? A.&lt;image_2&gt; B.&lt;image_3&gt; C.&lt;image_4&gt; D.&lt;image_5&gt;
            </div>
            <div class="img-placeholder">image_1 ~ image_5</div>
            <div class="example-answer">Answer: B</div>
            <div class="example-meta">Subject:Solid Geometry | Difficulty: Medium | Image Relevance: Mutually Dependent</div>
        </div>

        <div class="example-block">
            <h4>Free-Form: Single-Step</h4>
            <div class="example-question">
                Question: On a grid composed of squares with side length 1, each vertex of squares is called a lattice point. A movement from one lattice point to another is ‚àö5 units away is called a knight's move. In a 3 √ó 3 square grid (&lt;image_1&gt;), from point A, a knight's move can reach points B, C,D, E. Given a 25 √ó 25 square grid (&lt;image_2&gt;), the minimum number of knight's moves to reach the opposite vertex N from the M is
            </div>
            <div class="img-placeholder">image_1 ~ image_2</div>
            <div class="example-answer">Answer: 12</div>
            <div class="example-meta">Subject:Combinatorics | Difficulty: Medium | Image Relevance: Mutually Dependent</div>
        </div>
    </section>

    <!-- ÂÆûÈ™åÁªìÊûú -->
    <section>
        <h2>Experiment Results</h2>
        <h3>Main Results</h3>
        <p>We evaluate model performances across multiple question types, including choice problem set, single-step free-form set, and multi-step problem set (with SAR and QCR metrics). Full results are available in the paper.</p>

        <h3>More Results</h3>
        <div class="chart-row">
            <div class="chart-item">
                <div class="chart-img">
                    <div class="img-placeholder" style="height: 250px;">
                        (a) Result decomposition across question difficulty levels
                    </div>
                </div>
                <div class="chart-caption">(a) Result decomposition across question difficulty levels</div>
            </div>
            <div class="chart-item">
                <div class="chart-img">
                    <div class="img-placeholder" style="height: 250px;">
                        (b) Model Performance Evaluation for Original, CoT, and CoT with 2-shot configurations
                    </div>
                </div>
                <div class="chart-caption">(b) Original vs CoT vs CoT&2-shot Performance</div>
            </div>
        </div>
    </section>

    <!-- BibTeX -->
    <section>
        <h2>BibTeX</h2>
        <pre>
@inproceedings{wang2025mv,
  title={Mv-math: Evaluating multimodal math reasoning in multi-visual contexts},
  author={Wang, Peijie and Li, Zhong-Zhi and Yin, Fei and Ran, Dekang and Liu, Cheng-Lin},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={19541--19551},
  year={2025}
}
        </pre>
    </section>

    <!-- È°µËÑö -->
    <footer>
        <div class="footer-logos">
            <div>
                <div class="img-placeholder" style="width: 180px; height: 80px;">
                    Institute of Automation Chinese Academy of Sciences
                </div>
                <p>‰∏≠ÂõΩÁßëÂ≠¶Èô¢Ëá™Âä®ÂåñÁ†îÁ©∂ÊâÄ</p>
            </div>
            <div>
                <div class="img-placeholder" style="width: 180px; height: 80px;">
                    University of Chinese Academy of Sciences
                </div>
                <p>‰∏≠ÂõΩÁßëÂ≠¶Èô¢Â§ßÂ≠¶</p>
            </div>
        </div>
        <p>¬© 2025 MV-MATH Team. All Rights Reserved.</p>
    </footer>

    <!-- ÁÆÄÂçïÁöÑJSËÑöÊú¨Áî®‰∫éËÆæÁΩÆÈìæÊé•Âú∞ÂùÄ -->
    <script>
        // Âú®ËøôÈáåËÆæÁΩÆÂÆûÈôÖÁöÑÈìæÊé•Âú∞ÂùÄ
        document.getElementById('btn-pdf').href = 'https://arxiv.org/abs/xxxx.xxxxx'; // ÊõøÊç¢‰∏∫ÂÆûÈôÖPDFÈìæÊé•
        document.getElementById('btn-code').href = 'https://github.com/eternal8080/MV-MATH'; // ÊõøÊç¢‰∏∫ÂÆûÈôÖGitHubÈìæÊé•
        document.getElementById('btn-demo').href = '#'; // ÊõøÊç¢‰∏∫ÂÆûÈôÖDemoÈìæÊé•
    </script>
</body>
</html>
